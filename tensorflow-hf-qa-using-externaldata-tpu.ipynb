{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03667,
     "end_time": "2021-09-03T05:37:25.493935",
     "exception": false,
     "start_time": "2021-09-03T05:37:25.457265",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "# Competition Rules:\n",
    "- CPU Notebook <= 5 hours run-time\n",
    "-GPU Notebook <= 5 hours run-time\n",
    "-Internet access disabled\n",
    "- Freely & publicly available external data is allowed, including pre-trained models\n",
    "- Submission file must be named submission.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.048676,
     "end_time": "2021-09-03T05:37:25.578702",
     "exception": false,
     "start_time": "2021-09-03T05:37:25.530026",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Competition Metrics:\n",
    "The metric in this competition is the word-level Jaccard score\n",
    "\n",
    "`def jaccard(str1, str2): \n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.040582,
     "end_time": "2021-09-03T05:37:25.666877",
     "exception": false,
     "start_time": "2021-09-03T05:37:25.626295",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Ref:\n",
    "- https://keras.io/examples/nlp/text_extraction_with_bert/\n",
    "- https://github.com/huggingface/notebooks/blob/master/examples/question_answering.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.036743,
     "end_time": "2021-09-03T05:37:25.740057",
     "exception": false,
     "start_time": "2021-09-03T05:37:25.703314",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### External Datasets\n",
    "- This Notebook uses @rhtsingh's hindi dataset: [Hindi External](https://www.kaggle.com/rhtsingh/external-data-mlqa-xquad-preprocessing/data)\n",
    "- For Tamil, the dataset i have created: [Tamil External](https://www.kaggle.com/msafi04/squad-translated-to-tamil-for-chaii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-09-03T05:37:25.833326Z",
     "iopub.status.busy": "2021-09-03T05:37:25.832547Z",
     "iopub.status.idle": "2021-09-03T05:37:26.999196Z",
     "shell.execute_reply": "2021-09-03T05:37:26.998557Z",
     "shell.execute_reply.started": "2021-09-03T04:59:23.616730Z"
    },
    "papermill": {
     "duration": 1.222994,
     "end_time": "2021-09-03T05:37:26.999358",
     "exception": false,
     "start_time": "2021-09-03T05:37:25.776364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['squad-translated-to-tamil-for-chaii', 'jplu-tf-xlm-roberta-large', 'mlqa-hindi-processed', 'chaii-hindi-and-tamil-question-answering']\n",
      "2021-09-03 05:37:26.993247\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import collections\n",
    "\n",
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import json\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 8)\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "sns.set_palette('Set3_r')\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 20, \"display.max_columns\", None)\n",
    "\n",
    "print(os.listdir('../input/'))\n",
    "        \n",
    "from time import time, strftime, gmtime\n",
    "start = time()\n",
    "import datetime\n",
    "print(str(datetime.datetime.now()))\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action = 'ignore', category = Warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-03T05:37:27.078277Z",
     "iopub.status.busy": "2021-09-03T05:37:27.077680Z",
     "iopub.status.idle": "2021-09-03T05:37:28.072574Z",
     "shell.execute_reply": "2021-09-03T05:37:28.071954Z",
     "shell.execute_reply.started": "2021-09-03T04:59:39.712900Z"
    },
    "papermill": {
     "duration": 1.036024,
     "end_time": "2021-09-03T05:37:28.072722",
     "exception": false,
     "start_time": "2021-09-03T05:37:27.036698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1114, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>903deec17</td>\n",
       "      <td>ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...</td>\n",
       "      <td>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</td>\n",
       "      <td>206</td>\n",
       "      <td>53</td>\n",
       "      <td>tamil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d9841668c</td>\n",
       "      <td>காளிதாசன் (தேவநாகரி: कालिदास) சமஸ்கிருத இலக்கி...</td>\n",
       "      <td>காளிதாசன் எங்கு பிறந்தார்?</td>\n",
       "      <td>காசுமீரில்</td>\n",
       "      <td>2358</td>\n",
       "      <td>tamil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29d154b56</td>\n",
       "      <td>சர் அலெக்ஸாண்டர் ஃபிளெமிங் (Sir Alexander Flem...</td>\n",
       "      <td>பென்சிலின் கண்டுபிடித்தவர் யார்?</td>\n",
       "      <td>சர் அலெக்ஸாண்டர் ஃபிளெமிங்</td>\n",
       "      <td>0</td>\n",
       "      <td>tamil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41660850a</td>\n",
       "      <td>குழந்தையின் அழுகையை  நிறுத்தவும், தூங்க வைக்கவ...</td>\n",
       "      <td>தமிழ்நாட்டில் குழந்தைகளை தூங்க வைக்க பாடும் பா...</td>\n",
       "      <td>தாலாட்டு</td>\n",
       "      <td>68</td>\n",
       "      <td>tamil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b29c82c22</td>\n",
       "      <td>சூரியக் குடும்பம் \\nசூரியக் குடும்பம் (Solar S...</td>\n",
       "      <td>பூமியின் அருகில் உள்ள விண்மீன் எது?</td>\n",
       "      <td>சூரியனும்</td>\n",
       "      <td>585</td>\n",
       "      <td>tamil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            context  \\\n",
       "0  903deec17  ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...   \n",
       "1  d9841668c  காளிதாசன் (தேவநாகரி: कालिदास) சமஸ்கிருத இலக்கி...   \n",
       "2  29d154b56  சர் அலெக்ஸாண்டர் ஃபிளெமிங் (Sir Alexander Flem...   \n",
       "3  41660850a  குழந்தையின் அழுகையை  நிறுத்தவும், தூங்க வைக்கவ...   \n",
       "4  b29c82c22  சூரியக் குடும்பம் \\nசூரியக் குடும்பம் (Solar S...   \n",
       "\n",
       "                                            question  \\\n",
       "0               மனித உடலில் எத்தனை எலும்புகள் உள்ளன?   \n",
       "1                         காளிதாசன் எங்கு பிறந்தார்?   \n",
       "2                   பென்சிலின் கண்டுபிடித்தவர் யார்?   \n",
       "3  தமிழ்நாட்டில் குழந்தைகளை தூங்க வைக்க பாடும் பா...   \n",
       "4                பூமியின் அருகில் உள்ள விண்மீன் எது?   \n",
       "\n",
       "                  answer_text  answer_start language  \n",
       "0                         206            53    tamil  \n",
       "1                  காசுமீரில்          2358    tamil  \n",
       "2  சர் அலெக்ஸாண்டர் ஃபிளெமிங்             0    tamil  \n",
       "3                    தாலாட்டு            68    tamil  \n",
       "4                   சூரியனும்           585    tamil  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('/kaggle/input/chaii-hindi-and-tamil-question-answering/train.csv')\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-03T05:37:28.153208Z",
     "iopub.status.busy": "2021-09-03T05:37:28.152486Z",
     "iopub.status.idle": "2021-09-03T05:37:28.177080Z",
     "shell.execute_reply": "2021-09-03T05:37:28.177691Z",
     "shell.execute_reply.started": "2021-09-03T04:59:42.180671Z"
    },
    "papermill": {
     "duration": 0.066725,
     "end_time": "2021-09-03T05:37:28.177857",
     "exception": false,
     "start_time": "2021-09-03T05:37:28.111132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22bff3dec</td>\n",
       "      <td>ज्वाला गुट्टा (जन्म: 7 सितंबर 1983; वर्धा, महा...</td>\n",
       "      <td>ज्वाला गुट्टा की माँ का नाम क्या है</td>\n",
       "      <td>hindi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>282758170</td>\n",
       "      <td>गूगल मानचित्र (Google Maps) (पूर्व में गूगल लो...</td>\n",
       "      <td>गूगल मैप्स कब लॉन्च किया गया था?</td>\n",
       "      <td>hindi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d60987e0e</td>\n",
       "      <td>गुस्ताव रॉबर्ट किरचॉफ़ (१२ मार्च १८२४ - १७ अक्...</td>\n",
       "      <td>गुस्ताव किरचॉफ का जन्म कब हुआ था?</td>\n",
       "      <td>hindi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f99c770dc</td>\n",
       "      <td>அலுமினியம் (ஆங்கிலம்: அலுமினியம்; வட அமெரிக்க ...</td>\n",
       "      <td>அலுமினியத்தின் அணு எண் என்ன?</td>\n",
       "      <td>tamil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40dec1964</td>\n",
       "      <td>கூட்டுறவு இயக்க வரலாறு, இங்கிலாந்து  நாட்டில் ...</td>\n",
       "      <td>இந்தியாவில் பசுமை புரட்சியின் தந்தை என்று கருத...</td>\n",
       "      <td>tamil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            context  \\\n",
       "0  22bff3dec  ज्वाला गुट्टा (जन्म: 7 सितंबर 1983; वर्धा, महा...   \n",
       "1  282758170  गूगल मानचित्र (Google Maps) (पूर्व में गूगल लो...   \n",
       "2  d60987e0e  गुस्ताव रॉबर्ट किरचॉफ़ (१२ मार्च १८२४ - १७ अक्...   \n",
       "3  f99c770dc  அலுமினியம் (ஆங்கிலம்: அலுமினியம்; வட அமெரிக்க ...   \n",
       "4  40dec1964  கூட்டுறவு இயக்க வரலாறு, இங்கிலாந்து  நாட்டில் ...   \n",
       "\n",
       "                                            question language  \n",
       "0                ज्वाला गुट्टा की माँ का नाम क्या है    hindi  \n",
       "1                   गूगल मैप्स कब लॉन्च किया गया था?    hindi  \n",
       "2                  गुस्ताव किरचॉफ का जन्म कब हुआ था?    hindi  \n",
       "3                       அலுமினியத்தின் அணு எண் என்ன?    tamil  \n",
       "4  இந்தியாவில் பசுமை புரட்சியின் தந்தை என்று கருத...    tamil  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('/kaggle/input/chaii-hindi-and-tamil-question-answering/test.csv')\n",
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-03T05:37:28.256015Z",
     "iopub.status.busy": "2021-09-03T05:37:28.255375Z",
     "iopub.status.idle": "2021-09-03T05:37:28.275616Z",
     "shell.execute_reply": "2021-09-03T05:37:28.275125Z",
     "shell.execute_reply.started": "2021-09-03T04:59:43.260113Z"
    },
    "papermill": {
     "duration": 0.060087,
     "end_time": "2021-09-03T05:37:28.275763",
     "exception": false,
     "start_time": "2021-09-03T05:37:28.215676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22bff3dec</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>282758170</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d60987e0e</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f99c770dc</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40dec1964</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  PredictionString\n",
       "0  22bff3dec               NaN\n",
       "1  282758170               NaN\n",
       "2  d60987e0e               NaN\n",
       "3  f99c770dc               NaN\n",
       "4  40dec1964               NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv('/kaggle/input/chaii-hindi-and-tamil-question-answering/sample_submission.csv')\n",
    "print(sub.shape)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-03T05:37:28.357453Z",
     "iopub.status.busy": "2021-09-03T05:37:28.356847Z",
     "iopub.status.idle": "2021-09-03T05:37:28.731733Z",
     "shell.execute_reply": "2021-09-03T05:37:28.732233Z",
     "shell.execute_reply.started": "2021-09-03T04:59:44.847839Z"
    },
    "papermill": {
     "duration": 0.418122,
     "end_time": "2021-09-03T05:37:28.732428",
     "exception": false,
     "start_time": "2021-09-03T05:37:28.314306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5425, 5)\n"
     ]
    }
   ],
   "source": [
    "external_hindi1 = pd.read_csv('/kaggle/input/mlqa-hindi-processed/mlqa_hindi.csv')\n",
    "print(external_hindi1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-03T05:37:28.814961Z",
     "iopub.status.busy": "2021-09-03T05:37:28.814355Z",
     "iopub.status.idle": "2021-09-03T05:37:28.890390Z",
     "shell.execute_reply": "2021-09-03T05:37:28.891086Z",
     "shell.execute_reply.started": "2021-09-03T04:59:46.274583Z"
    },
    "papermill": {
     "duration": 0.119593,
     "end_time": "2021-09-03T05:37:28.891285",
     "exception": false,
     "start_time": "2021-09-03T05:37:28.771692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1190, 5)\n"
     ]
    }
   ],
   "source": [
    "external_hindi2 = pd.read_csv('/kaggle/input/mlqa-hindi-processed/xquad.csv')\n",
    "print(external_hindi2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-03T05:37:28.975185Z",
     "iopub.status.busy": "2021-09-03T05:37:28.974210Z",
     "iopub.status.idle": "2021-09-03T05:37:28.983560Z",
     "shell.execute_reply": "2021-09-03T05:37:28.984132Z",
     "shell.execute_reply.started": "2021-09-03T04:59:47.424251Z"
    },
    "papermill": {
     "duration": 0.052782,
     "end_time": "2021-09-03T05:37:28.984305",
     "exception": false,
     "start_time": "2021-09-03T05:37:28.931523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "External hindi dataset...\n",
      "(6615, 5)\n"
     ]
    }
   ],
   "source": [
    "print('External hindi dataset...')\n",
    "external_hindi = pd.concat([external_hindi1, external_hindi2])\n",
    "print(external_hindi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-03T05:37:29.067352Z",
     "iopub.status.busy": "2021-09-03T05:37:29.066385Z",
     "iopub.status.idle": "2021-09-03T05:37:29.340447Z",
     "shell.execute_reply": "2021-09-03T05:37:29.340980Z",
     "shell.execute_reply.started": "2021-09-03T05:00:29.877690Z"
    },
    "papermill": {
     "duration": 0.317213,
     "end_time": "2021-09-03T05:37:29.341162",
     "exception": false,
     "start_time": "2021-09-03T05:37:29.023949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "External Tamil dataset...\n",
      "(3567, 5)\n"
     ]
    }
   ],
   "source": [
    "print('External Tamil dataset...')\n",
    "external_tamil = pd.read_csv('/kaggle/input/squad-translated-to-tamil-for-chaii/squad_translated_tamil.csv')\n",
    "external_tamil['language'] = 'tamil'\n",
    "print(external_tamil.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-03T05:37:29.425594Z",
     "iopub.status.busy": "2021-09-03T05:37:29.424991Z",
     "iopub.status.idle": "2021-09-03T05:37:29.447227Z",
     "shell.execute_reply": "2021-09-03T05:37:29.447859Z",
     "shell.execute_reply.started": "2021-09-03T05:00:38.069893Z"
    },
    "papermill": {
     "duration": 0.066034,
     "end_time": "2021-09-03T05:37:29.448075",
     "exception": false,
     "start_time": "2021-09-03T05:37:29.382041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined External dataset...\n",
      "(10182, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"वेस्ट साइड ऑफ़ फ्रेस्नो, जिसे अक्सर \"दक्षिण-प...</td>\n",
       "      <td>फ्रेस्नो के पश्चिमी हिस्से के क्षेत्र में रहने...</td>\n",
       "      <td>हमोंग या लाओटियन</td>\n",
       "      <td>522.0</td>\n",
       "      <td>hindi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>उत्तरी अमेरिका में ह्यूगनॉट्स अधिकतर समूह (या ...</td>\n",
       "      <td>बड़े पैमाने पर ह्यूगनॉट्स प्रवासी; उत्तर अमेरि...</td>\n",
       "      <td>अपने फ्रांसीसी समुदाय के बाहर विवाह किया</td>\n",
       "      <td>199.0</td>\n",
       "      <td>hindi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>முத்து துறைமுகத்தின் மீதான தாக்குதலுக்கு சில ம...</td>\n",
       "      <td>மார்ஷல் தீவுகளில் ஜப்பானிய கடற்படை என்ன?</td>\n",
       "      <td>6 வது கடற்படை</td>\n",
       "      <td>80.0</td>\n",
       "      <td>tamil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>எவர்டன் வழக்கமாக உள்நாட்டில் மற்றும் ஐரோப்பிய ...</td>\n",
       "      <td>2009 ஆம் ஆண்டு முதல், எவர்டன் எஃப்.சி. எஃப்.சி...</td>\n",
       "      <td>1985</td>\n",
       "      <td>482.0</td>\n",
       "      <td>tamil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ஒரு சில குடும்பங்கள் பெரிய தோட்டங்களை சொந்தமாக...</td>\n",
       "      <td>இந்த குழு பெரும்பாலும் சுரண்டப்பட்டு, சட்டபூர்...</td>\n",
       "      <td>பாட்டாளி வர்க்கம்</td>\n",
       "      <td>464.0</td>\n",
       "      <td>tamil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  \"वेस्ट साइड ऑफ़ फ्रेस्नो, जिसे अक्सर \"दक्षिण-प...   \n",
       "1  उत्तरी अमेरिका में ह्यूगनॉट्स अधिकतर समूह (या ...   \n",
       "2  முத்து துறைமுகத்தின் மீதான தாக்குதலுக்கு சில ம...   \n",
       "3  எவர்டன் வழக்கமாக உள்நாட்டில் மற்றும் ஐரோப்பிய ...   \n",
       "4  ஒரு சில குடும்பங்கள் பெரிய தோட்டங்களை சொந்தமாக...   \n",
       "\n",
       "                                            question  \\\n",
       "0  फ्रेस्नो के पश्चिमी हिस्से के क्षेत्र में रहने...   \n",
       "1  बड़े पैमाने पर ह्यूगनॉट्स प्रवासी; उत्तर अमेरि...   \n",
       "2           மார்ஷல் தீவுகளில் ஜப்பானிய கடற்படை என்ன?   \n",
       "3  2009 ஆம் ஆண்டு முதல், எவர்டன் எஃப்.சி. எஃப்.சி...   \n",
       "4  இந்த குழு பெரும்பாலும் சுரண்டப்பட்டு, சட்டபூர்...   \n",
       "\n",
       "                                answer_text  answer_start language  \n",
       "0                          हमोंग या लाओटियन         522.0    hindi  \n",
       "1  अपने फ्रांसीसी समुदाय के बाहर विवाह किया         199.0    hindi  \n",
       "2                             6 வது கடற்படை          80.0    tamil  \n",
       "3                                      1985         482.0    tamil  \n",
       "4                         பாட்டாளி வர்க்கம்         464.0    tamil  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Combined External dataset...')\n",
    "external_df = pd.concat([external_hindi, external_tamil])\n",
    "external_df = external_df.sample(frac = 1).reset_index(drop = True)\n",
    "print(external_df.shape)\n",
    "external_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-03T05:37:29.534979Z",
     "iopub.status.busy": "2021-09-03T05:37:29.534279Z",
     "iopub.status.idle": "2021-09-03T05:37:29.640907Z",
     "shell.execute_reply": "2021-09-03T05:37:29.641390Z",
     "shell.execute_reply.started": "2021-09-03T05:02:21.755989Z"
    },
    "papermill": {
     "duration": 0.151095,
     "end_time": "2021-09-03T05:37:29.641575",
     "exception": false,
     "start_time": "2021-09-03T05:37:29.490480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del external_hindi1, external_hindi2, external_hindi, external_tamil\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-03T05:37:29.727461Z",
     "iopub.status.busy": "2021-09-03T05:37:29.726863Z",
     "iopub.status.idle": "2021-09-03T05:37:30.044091Z",
     "shell.execute_reply": "2021-09-03T05:37:30.043588Z",
     "shell.execute_reply.started": "2021-09-03T05:02:54.292140Z"
    },
    "papermill": {
     "duration": 0.361279,
     "end_time": "2021-09-03T05:37:30.044229",
     "exception": false,
     "start_time": "2021-09-03T05:37:29.682950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "sns.countplot(x = 'language', data = external_df, ax = ax1).set_title('External Dataset Language Counts')\n",
    "for p in ax1.patches:\n",
    "    ax1.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.005))\n",
    "sns.countplot(x = 'language', data = test, ax = ax2).set_title('Test Language Counts')\n",
    "for p in ax2.patches:\n",
    "    ax2.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.005))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.042671,
     "end_time": "2021-09-03T05:37:30.129563",
     "exception": false,
     "start_time": "2021-09-03T05:37:30.086892",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Huggingface TF XLM RoBerta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-03T05:37:30.220587Z",
     "iopub.status.busy": "2021-09-03T05:37:30.219965Z",
     "iopub.status.idle": "2021-09-03T05:37:30.242827Z",
     "shell.execute_reply": "2021-09-03T05:37:30.242172Z",
     "shell.execute_reply.started": "2021-09-01T07:13:04.212114Z"
    },
    "papermill": {
     "duration": 0.070625,
     "end_time": "2021-09-03T05:37:30.242961",
     "exception": false,
     "start_time": "2021-09-03T05:37:30.172336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "hparams = {\n",
    "    'DEVICE': 'TPU',\n",
    "    'EPOCHS': 3,\n",
    "    'MODEL_2': '../input/jplu-tf-xlm-roberta-large',\n",
    "    'N_FOLDS': 5,\n",
    "    'SEED': 777,\n",
    "    'VERBOSE': 1,\n",
    "    'BATCH_SIZE': 16,\n",
    "    'MAX_LENGTH': 512,\n",
    "    'DOC_STRIDE': 128\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-03T05:37:30.332770Z",
     "iopub.status.busy": "2021-09-03T05:37:30.332094Z",
     "iopub.status.idle": "2021-09-03T05:37:37.175803Z",
     "shell.execute_reply": "2021-09-03T05:37:37.176257Z",
     "shell.execute_reply.started": "2021-09-01T07:13:11.772547Z"
    },
    "papermill": {
     "duration": 6.890809,
     "end_time": "2021-09-03T05:37:37.176443",
     "exception": false,
     "start_time": "2021-09-03T05:37:30.285634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n",
      "4.6.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, TFXLMRobertaForQuestionAnswering, TFXLMRobertaModel\n",
    "\n",
    "print(tf.__version__)\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-03T05:37:37.267497Z",
     "iopub.status.busy": "2021-09-03T05:37:37.266547Z",
     "iopub.status.idle": "2021-09-03T05:37:37.269007Z",
     "shell.execute_reply": "2021-09-03T05:37:37.269495Z",
     "shell.execute_reply.started": "2021-09-01T07:13:20.490483Z"
    },
    "papermill": {
     "duration": 0.050369,
     "end_time": "2021-09-03T05:37:37.269666",
     "exception": false,
     "start_time": "2021-09-03T05:37:37.219297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = hparams['SEED']\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-03T05:37:37.359394Z",
     "iopub.status.busy": "2021-09-03T05:37:37.358766Z",
     "iopub.status.idle": "2021-09-03T05:37:37.361461Z",
     "shell.execute_reply": "2021-09-03T05:37:37.360977Z",
     "shell.execute_reply.started": "2021-09-01T07:13:21.676618Z"
    },
    "papermill": {
     "duration": 0.04918,
     "end_time": "2021-09-03T05:37:37.361596",
     "exception": false,
     "start_time": "2021-09-03T05:37:37.312416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_checkpoint = hparams['MODEL_2']\n",
    "batch_size = hparams['BATCH_SIZE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-03T05:37:37.452359Z",
     "iopub.status.busy": "2021-09-03T05:37:37.451695Z",
     "iopub.status.idle": "2021-09-03T05:37:39.595511Z",
     "shell.execute_reply": "2021-09-03T05:37:39.596177Z",
     "shell.execute_reply.started": "2021-09-01T07:13:23.216038Z"
    },
    "papermill": {
     "duration": 2.191473,
     "end_time": "2021-09-03T05:37:39.596352",
     "exception": false,
     "start_time": "2021-09-03T05:37:37.404879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreTrainedTokenizerFast(name_or_path='../input/jplu-tf-xlm-roberta-large', vocab_size=250002, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True)})\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_special_tokens = True)\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-03T05:37:39.688838Z",
     "iopub.status.busy": "2021-09-03T05:37:39.688113Z",
     "iopub.status.idle": "2021-09-03T05:38:20.497734Z",
     "shell.execute_reply": "2021-09-03T05:38:20.498381Z",
     "shell.execute_reply.started": "2021-08-31T05:54:01.153179Z"
    },
    "papermill": {
     "duration": 40.858624,
     "end_time": "2021-09-03T05:38:20.498587",
     "exception": false,
     "start_time": "2021-09-03T05:37:39.639963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14973"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['context_num_tokens'] = train['context'].apply(lambda x: len(tokenizer(x)['input_ids']))\n",
    "train['context_num_tokens'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-03T05:38:20.603475Z",
     "iopub.status.busy": "2021-09-03T05:38:20.602511Z",
     "iopub.status.idle": "2021-09-03T05:38:20.837967Z",
     "shell.execute_reply": "2021-09-03T05:38:20.837383Z",
     "shell.execute_reply.started": "2021-08-31T05:54:43.20899Z"
    },
    "papermill": {
     "duration": 0.292985,
     "end_time": "2021-09-03T05:38:20.838116",
     "exception": false,
     "start_time": "2021-09-03T05:38:20.545131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['context_num_tokens'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.043882,
     "end_time": "2021-09-03T05:38:20.927739",
     "exception": false,
     "start_time": "2021-09-03T05:38:20.883857",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- The context length is too long, it has to be split into pieces before processing\n",
    "- Usually in NLP tasks long documents are truncated but in QA tasks truncating 'context' would lead to loss of answer\n",
    "- To avoid this, the long context is split into many input features each of length less than the max_length parameter\n",
    "- And if answer is at the split, we use overlapping of split features which is controlled by the parameter doc_stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-03T05:38:21.023904Z",
     "iopub.status.busy": "2021-09-03T05:38:21.023239Z",
     "iopub.status.idle": "2021-09-03T05:38:21.042322Z",
     "shell.execute_reply": "2021-09-03T05:38:21.041810Z",
     "shell.execute_reply.started": "2021-09-01T07:13:40.804104Z"
    },
    "papermill": {
     "duration": 0.06969,
     "end_time": "2021-09-03T05:38:21.042480",
     "exception": false,
     "start_time": "2021-09-03T05:38:20.972790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1114, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>language</th>\n",
       "      <th>context_num_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0231ad0ec</td>\n",
       "      <td>தமிழ்நாட்டில் மேற்கொள்ளப்படும் வேளாண்மையும் அத...</td>\n",
       "      <td>தமிழ்நாட்டில் அதிகமான ரோஜா பூ எங்கு சாகுபடி செ...</td>\n",
       "      <td>ஓசூர்</td>\n",
       "      <td>1731</td>\n",
       "      <td>tamil</td>\n",
       "      <td>1289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80452bc4d</td>\n",
       "      <td>கால்வாய் எனப்படுவது நீர்ப்பாசனத்துக்காக கால்வா...</td>\n",
       "      <td>உலகின் மிகப்பெரிய மனிதனால் உருவாக்கப்பட்ட கால்...</td>\n",
       "      <td>பெரும்</td>\n",
       "      <td>1928</td>\n",
       "      <td>tamil</td>\n",
       "      <td>2778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a48ae7027</td>\n",
       "      <td>रजनीकान्त ();(मराठी:शिवाजीराव गायकवाड) एक भारत...</td>\n",
       "      <td>तमिल सिनेमा के अभिनेता रजनीकांत का पूरा नाम क्...</td>\n",
       "      <td>शिवाजीराव गायकवाड</td>\n",
       "      <td>20</td>\n",
       "      <td>hindi</td>\n",
       "      <td>1521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6fc07dbd9</td>\n",
       "      <td>ஜெயமோகன் (Jeyamohan), பிறப்பு: 22 ஏப்ரல் 1962)...</td>\n",
       "      <td>எழுத்தாளர் ஜெயமோகனின் சொந்த ஊர் எது?</td>\n",
       "      <td>குமரி மாவட்டம் விளவங்கோடு வட்டம், திருவரம்பு</td>\n",
       "      <td>359</td>\n",
       "      <td>tamil</td>\n",
       "      <td>3201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33f5a537d</td>\n",
       "      <td>लीबिया (Arabic: ليبيا‎), आधिकारिक तौर पर 'महान...</td>\n",
       "      <td>लीबिया की राजधानी क्या है?</td>\n",
       "      <td>त्रिपोली</td>\n",
       "      <td>615</td>\n",
       "      <td>hindi</td>\n",
       "      <td>1922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            context  \\\n",
       "0  0231ad0ec  தமிழ்நாட்டில் மேற்கொள்ளப்படும் வேளாண்மையும் அத...   \n",
       "1  80452bc4d  கால்வாய் எனப்படுவது நீர்ப்பாசனத்துக்காக கால்வா...   \n",
       "2  a48ae7027  रजनीकान्त ();(मराठी:शिवाजीराव गायकवाड) एक भारत...   \n",
       "3  6fc07dbd9  ஜெயமோகன் (Jeyamohan), பிறப்பு: 22 ஏப்ரல் 1962)...   \n",
       "4  33f5a537d  लीबिया (Arabic: ليبيا‎), आधिकारिक तौर पर 'महान...   \n",
       "\n",
       "                                            question  \\\n",
       "0  தமிழ்நாட்டில் அதிகமான ரோஜா பூ எங்கு சாகுபடி செ...   \n",
       "1  உலகின் மிகப்பெரிய மனிதனால் உருவாக்கப்பட்ட கால்...   \n",
       "2  तमिल सिनेमा के अभिनेता रजनीकांत का पूरा नाम क्...   \n",
       "3               எழுத்தாளர் ஜெயமோகனின் சொந்த ஊர் எது?   \n",
       "4                         लीबिया की राजधानी क्या है?   \n",
       "\n",
       "                                    answer_text  answer_start language  \\\n",
       "0                                         ஓசூர்          1731    tamil   \n",
       "1                                        பெரும்          1928    tamil   \n",
       "2                             शिवाजीराव गायकवाड            20    hindi   \n",
       "3  குமரி மாவட்டம் விளவங்கோடு வட்டம், திருவரம்பு           359    tamil   \n",
       "4                                      त्रिपोली           615    hindi   \n",
       "\n",
       "   context_num_tokens  \n",
       "0                1289  \n",
       "1                2778  \n",
       "2                1521  \n",
       "3                3201  \n",
       "4                1922  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.sample(frac = 1, random_state = 2021).reset_index(drop = True)\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-03T05:38:21.136578Z",
     "iopub.status.busy": "2021-09-03T05:38:21.135945Z",
     "iopub.status.idle": "2021-09-03T05:38:21.159328Z",
     "shell.execute_reply": "2021-09-03T05:38:21.158840Z",
     "shell.execute_reply.started": "2021-09-01T07:13:45.060136Z"
    },
    "papermill": {
     "duration": 0.071677,
     "end_time": "2021-09-03T05:38:21.159483",
     "exception": false,
     "start_time": "2021-09-03T05:38:21.087806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>language</th>\n",
       "      <th>context_num_tokens</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0231ad0ec</td>\n",
       "      <td>தமிழ்நாட்டில் மேற்கொள்ளப்படும் வேளாண்மையும் அத...</td>\n",
       "      <td>தமிழ்நாட்டில் அதிகமான ரோஜா பூ எங்கு சாகுபடி செ...</td>\n",
       "      <td>ஓசூர்</td>\n",
       "      <td>1731</td>\n",
       "      <td>tamil</td>\n",
       "      <td>1289</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80452bc4d</td>\n",
       "      <td>கால்வாய் எனப்படுவது நீர்ப்பாசனத்துக்காக கால்வா...</td>\n",
       "      <td>உலகின் மிகப்பெரிய மனிதனால் உருவாக்கப்பட்ட கால்...</td>\n",
       "      <td>பெரும்</td>\n",
       "      <td>1928</td>\n",
       "      <td>tamil</td>\n",
       "      <td>2778</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            context  \\\n",
       "0  0231ad0ec  தமிழ்நாட்டில் மேற்கொள்ளப்படும் வேளாண்மையும் அத...   \n",
       "1  80452bc4d  கால்வாய் எனப்படுவது நீர்ப்பாசனத்துக்காக கால்வா...   \n",
       "\n",
       "                                            question answer_text  \\\n",
       "0  தமிழ்நாட்டில் அதிகமான ரோஜா பூ எங்கு சாகுபடி செ...       ஓசூர்   \n",
       "1  உலகின் மிகப்பெரிய மனிதனால் உருவாக்கப்பட்ட கால்...      பெரும்   \n",
       "\n",
       "   answer_start language  context_num_tokens  kfold  \n",
       "0          1731    tamil                1289      3  \n",
       "1          1928    tamil                2778      4  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split data to folds\n",
    "n_folds = hparams['N_FOLDS']\n",
    "train['kfold'] = -1\n",
    "\n",
    "skf = StratifiedKFold(n_splits = n_folds, shuffle = True, random_state = SEED)\n",
    "for fold, (trn_idx, val_idx) in enumerate(skf.split(X = train, y = train['language'].values)):\n",
    "    train.loc[val_idx, 'kfold'] = fold\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.04695,
     "end_time": "2021-09-03T05:38:21.253404",
     "exception": false,
     "start_time": "2021-09-03T05:38:21.206454",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Set TPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-03T05:38:21.361237Z",
     "iopub.status.busy": "2021-09-03T05:38:21.360376Z",
     "iopub.status.idle": "2021-09-03T05:38:27.140231Z",
     "shell.execute_reply": "2021-09-03T05:38:27.139564Z",
     "shell.execute_reply.started": "2021-09-01T07:13:52.788403Z"
    },
    "papermill": {
     "duration": 5.841743,
     "end_time": "2021-09-03T05:38:27.140374",
     "exception": false,
     "start_time": "2021-09-03T05:38:21.298631",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connecting to TPU...\n",
      "Running on TPU  grpc://10.0.0.2:8470\n",
      "initializing  TPU ...\n",
      "TPU initialized\n",
      "REPLICAS: 8\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'TPU'\n",
    "\n",
    "if DEVICE == \"TPU\":\n",
    "    print(\"connecting to TPU...\")\n",
    "    try:\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "        print('Running on TPU ', tpu.master())\n",
    "    except ValueError:\n",
    "        print(\"Could not connect to TPU\")\n",
    "        tpu = None\n",
    "\n",
    "    if tpu:\n",
    "        try:\n",
    "            print(\"initializing  TPU ...\")\n",
    "            tf.config.experimental_connect_to_cluster(tpu)\n",
    "            tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "            print(\"TPU initialized\")\n",
    "        except _:\n",
    "            print(\"failed to initialize TPU\")\n",
    "    else:\n",
    "        DEVICE = \"GPU\"\n",
    "\n",
    "if DEVICE != \"TPU\":\n",
    "    print(\"Using default strategy for CPU and single GPU\")\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "if DEVICE == \"GPU\":\n",
    "    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "    \n",
    "\n",
    "AUTO     = tf.data.experimental.AUTOTUNE\n",
    "REPLICAS = strategy.num_replicas_in_sync\n",
    "\n",
    "print(f'REPLICAS: {REPLICAS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-03T05:38:27.239956Z",
     "iopub.status.busy": "2021-09-03T05:38:27.239192Z",
     "iopub.status.idle": "2021-09-03T05:38:27.241836Z",
     "shell.execute_reply": "2021-09-03T05:38:27.241196Z",
     "shell.execute_reply.started": "2021-09-01T07:13:58.56482Z"
    },
    "papermill": {
     "duration": 0.053882,
     "end_time": "2021-09-03T05:38:27.241977",
     "exception": false,
     "start_time": "2021-09-03T05:38:27.188095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_length = hparams['MAX_LENGTH'] #The maximum length of a feature (question and context)\n",
    "doc_stride = hparams['DOC_STRIDE'] #The authorized overlap between two part of the context when splitting it if needed.\n",
    "\n",
    "pad_on_right = tokenizer.padding_side == \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-03T05:38:27.350837Z",
     "iopub.status.busy": "2021-09-03T05:38:27.345806Z",
     "iopub.status.idle": "2021-09-03T05:38:27.354647Z",
     "shell.execute_reply": "2021-09-03T05:38:27.353983Z",
     "shell.execute_reply.started": "2021-09-01T07:13:58.57238Z"
    },
    "papermill": {
     "duration": 0.065934,
     "end_time": "2021-09-03T05:38:27.354791",
     "exception": false,
     "start_time": "2021-09-03T05:38:27.288857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_training(examples):\n",
    "    examples['question'] = [q.lstrip() for q in examples['question']] #remove leading white space\n",
    "    examples['question'] = [q.rstrip('?') for q in examples['question']] #remove '?' from the questions\n",
    "    \n",
    "    \"\"\"Tokenize our examples with truncation and padding, but keep the overflows using a stride. This results\n",
    "    in one example possible giving several features when a context is long, each of those features having a\n",
    "    context that overlaps a bit the context of the previous feature.\"\"\"\n",
    "    \n",
    "    tokenized_examples = tokenizer(\n",
    "                list(examples['question' if pad_on_right else 'context'].values),\n",
    "                list(examples['context' if pad_on_right else 'question'].values),\n",
    "                truncation = 'only_second' if pad_on_right else 'only_first',\n",
    "                max_length = max_length,\n",
    "                stride = doc_stride,\n",
    "                return_overflowing_tokens = True,\n",
    "                return_offsets_mapping = True,\n",
    "                padding = 'max_length'\n",
    "            )\n",
    "    #Since one example might give us several features if it has a long context, we need a map from a feature to\n",
    "    #its corresponding example. This key gives us just that.\n",
    "    \n",
    "    sample_mapping = tokenized_examples.pop('overflow_to_sample_mapping')\n",
    "    \n",
    "    #The offset mappings will give us a map from token to character position in the original context. This will\n",
    "    #help us compute the start_positions and end_positions.\n",
    "    \n",
    "    offset_mapping = tokenized_examples.pop('offset_mapping')\n",
    "    \n",
    "    tokenized_examples['start_positions'] = []\n",
    "    tokenized_examples['end_positions'] = []\n",
    "\n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        # We will label impossible answers with the index of the CLS token.\n",
    "        input_ids = tokenized_examples['input_ids'][i]\n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "        \n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "        \n",
    "        #One example can give several spans, this is the index of the example containing this span of text.\n",
    "        sample_index = sample_mapping[i]\n",
    "        answers = examples.loc[sample_index, 'answer_text']\n",
    "        start_char = examples.loc[sample_index, 'answer_start']\n",
    "        \n",
    "        # If no answers are given, set the cls_index as answer.\n",
    "        if start_char is None:\n",
    "            tokenized_examples['start_positions'].append(cls_index)\n",
    "            tokenized_examples['end_positions'].append(cls_index)\n",
    "        else:\n",
    "            # Start/end character idx of the answer in the text.\n",
    "            end_char = start_char + len(answers)\n",
    "            \n",
    "             #Start token idx of the current span in the text.\n",
    "            token_start_index = 0\n",
    "            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n",
    "                token_start_index += 1\n",
    "            # End token index of the current span in the text.\n",
    "            token_end_index = len(input_ids) - 1\n",
    "            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n",
    "                token_end_index -= 1\n",
    "            #Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
    "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "                tokenized_examples['start_positions'].append(cls_index)\n",
    "                tokenized_examples['end_positions'].append(cls_index)\n",
    "            else:\n",
    "                #Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n",
    "                #Note: we could go after the last offset if the answer is the last word (edge case).\n",
    "                \n",
    "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "                    token_start_index += 1\n",
    "                tokenized_examples['start_positions'].append(token_start_index - 1)\n",
    "                \n",
    "                while offsets[token_end_index][1] >= end_char:\n",
    "                    token_end_index -= 1\n",
    "                tokenized_examples['end_positions'].append(token_end_index + 1)\n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-03T05:38:27.459076Z",
     "iopub.status.busy": "2021-09-03T05:38:27.458377Z",
     "iopub.status.idle": "2021-09-03T05:38:27.461048Z",
     "shell.execute_reply": "2021-09-03T05:38:27.460501Z",
     "shell.execute_reply.started": "2021-09-01T07:14:00.194631Z"
    },
    "papermill": {
     "duration": 0.05925,
     "end_time": "2021-09-03T05:38:27.461193",
     "exception": false,
     "start_time": "2021-09-03T05:38:27.401943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_validation(examples):\n",
    "    examples['question'] = [q.lstrip() for q in examples['question']]\n",
    "    examples['question'] = [q.rstrip('?') for q in examples['question']]\n",
    "    \n",
    "    tokenized_examples = tokenizer(\n",
    "                list(examples['question' if pad_on_right else 'context'].values),\n",
    "                list(examples['context' if pad_on_right else 'question'].values),\n",
    "                truncation = 'only_second' if pad_on_right else 'only_first',\n",
    "                max_length = max_length,\n",
    "                stride = doc_stride,\n",
    "                return_overflowing_tokens = True,\n",
    "                return_offsets_mapping = True,\n",
    "                padding = 'max_length'\n",
    "            )\n",
    "    \n",
    "    sample_mapping = tokenized_examples.pop('overflow_to_sample_mapping')\n",
    "    \n",
    "    #id column from the dataset\n",
    "    tokenized_examples['example_id'] = []\n",
    "\n",
    "    for i in range(len(tokenized_examples['input_ids'])):\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "        context_index = 1 if pad_on_right else 0\n",
    "        sample_index = sample_mapping[i]\n",
    "        tokenized_examples['example_id'].append(examples.loc[sample_index, 'id'])\n",
    "        tokenized_examples['offset_mapping'][i] = [\n",
    "            (o if sequence_ids[k] == context_index else None)\n",
    "            for k, o in enumerate(tokenized_examples['offset_mapping'][i])\n",
    "        ]\n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-03T05:38:27.564848Z",
     "iopub.status.busy": "2021-09-03T05:38:27.563827Z",
     "iopub.status.idle": "2021-09-03T05:38:27.566976Z",
     "shell.execute_reply": "2021-09-03T05:38:27.566352Z",
     "shell.execute_reply.started": "2021-09-01T07:14:01.471564Z"
    },
    "papermill": {
     "duration": 0.059062,
     "end_time": "2021-09-03T05:38:27.567109",
     "exception": false,
     "start_time": "2021-09-03T05:38:27.508047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_tf_dataset(df, batch_size = 4, flag = 'train'):\n",
    "    \n",
    "    if flag == 'train':\n",
    "        features = prepare_training(df)\n",
    "    else:\n",
    "        features = prepare_validation(df)\n",
    "    \n",
    "    input_ids = features['input_ids']\n",
    "    attn_masks = features['attention_mask']\n",
    "    \n",
    "    if flag == 'train':\n",
    "        start_positions = features['start_positions']\n",
    "        end_positions = features['end_positions']\n",
    "        \n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((input_ids, attn_masks, start_positions, end_positions))\n",
    "        train_dataset = train_dataset.map(lambda x1, x2, y1, y2: ({'input_ids': x1, 'attention_mask': x2}, {'start_positions': y1, 'end_positions': y2}))\n",
    "        train_dataset = train_dataset.batch(batch_size)\n",
    "        train_dataset = train_dataset.shuffle(1000)\n",
    "        train_dataset = train_dataset.prefetch(AUTO)\n",
    "        \n",
    "        return train_dataset, features\n",
    "    \n",
    "    elif flag == 'valid':\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((input_ids, attn_masks))\n",
    "        dataset = dataset.map(lambda x1, x2: ({'input_ids': x1, 'attention_mask': x2}))\n",
    "        dataset = dataset.batch(batch_size)\n",
    "        dataset = dataset.prefetch(buffer_size = AUTO)\n",
    "        \n",
    "        return dataset, features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.046208,
     "end_time": "2021-09-03T05:38:27.660143",
     "exception": false,
     "start_time": "2021-09-03T05:38:27.613935",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TF XLM RoBerta Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-03T05:38:27.764279Z",
     "iopub.status.busy": "2021-09-03T05:38:27.763587Z",
     "iopub.status.idle": "2021-09-03T05:38:27.766675Z",
     "shell.execute_reply": "2021-09-03T05:38:27.766056Z",
     "shell.execute_reply.started": "2021-09-01T07:14:03.796657Z"
    },
    "papermill": {
     "duration": 0.05998,
     "end_time": "2021-09-03T05:38:27.766816",
     "exception": false,
     "start_time": "2021-09-03T05:38:27.706836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    roberta = TFXLMRobertaModel.from_pretrained(model_checkpoint)\n",
    "    \n",
    "    input_ids = tf.keras.layers.Input(shape = (max_length, ), name = 'input_ids', dtype = tf.int32)\n",
    "    attention_mask = tf.keras.layers.Input(shape = (max_length, ), name = 'attention_mask', dtype = tf.int32)\n",
    "    \n",
    "    embeddings = roberta(input_ids = input_ids, attention_mask = attention_mask)[0]\n",
    "    \n",
    "    x1 = tf.keras.layers.Dropout(0.1)(embeddings) \n",
    "    x1 = tf.keras.layers.Dense(1, use_bias = False)(x1)\n",
    "    x1 = tf.keras.layers.Flatten()(x1)\n",
    "    x1 = tf.keras.layers.Activation('softmax', name = 'start_positions')(x1)\n",
    "    \n",
    "    x2 = tf.keras.layers.Dropout(0.1)(embeddings) \n",
    "    x2 = tf.keras.layers.Dense(1, use_bias = False)(x2)\n",
    "    x2 = tf.keras.layers.Flatten()(x2)\n",
    "    x2 = tf.keras.layers.Activation('softmax', name = 'end_positions')(x2)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs = [input_ids, attention_mask], outputs = [x1, x2])\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = 3e-5)\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False)\n",
    "    \n",
    "    model.compile(loss = [loss, loss], optimizer = optimizer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.046278,
     "end_time": "2021-09-03T05:38:27.859592",
     "exception": false,
     "start_time": "2021-09-03T05:38:27.813314",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-03T05:38:27.958790Z",
     "iopub.status.busy": "2021-09-03T05:38:27.958061Z",
     "iopub.status.idle": "2021-09-03T05:38:27.961132Z",
     "shell.execute_reply": "2021-09-03T05:38:27.960622Z",
     "shell.execute_reply.started": "2021-09-01T07:14:05.582127Z"
    },
    "papermill": {
     "duration": 0.05512,
     "end_time": "2021-09-03T05:38:27.961269",
     "exception": false,
     "start_time": "2021-09-03T05:38:27.906149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def jaccard(str1, str2): \n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.046306,
     "end_time": "2021-09-03T05:38:28.054097",
     "exception": false,
     "start_time": "2021-09-03T05:38:28.007791",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Post Process Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-03T05:38:28.165378Z",
     "iopub.status.busy": "2021-09-03T05:38:28.164332Z",
     "iopub.status.idle": "2021-09-03T05:38:28.167294Z",
     "shell.execute_reply": "2021-09-03T05:38:28.166806Z",
     "shell.execute_reply.started": "2021-09-01T07:14:07.246916Z"
    },
    "papermill": {
     "duration": 0.066612,
     "end_time": "2021-09-03T05:38:28.167453",
     "exception": false,
     "start_time": "2021-09-03T05:38:28.100841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def post_process_predictions(examples, features, start, end, n_best_size = 20, max_answer_length = 30):\n",
    "    \n",
    "    all_start_logits, all_end_logits = start, end\n",
    "    # Build a map example to its corresponding features.\n",
    "    example_id_to_index = {k: i for i, k in enumerate(examples['id'])}\n",
    "    features_per_example = collections.defaultdict(list)\n",
    "    \n",
    "    for i, feature in enumerate(features['example_id']):\n",
    "        features_per_example[example_id_to_index[feature]].append(i)\n",
    "\n",
    "    # The dictionaries we have to fill.\n",
    "    predictions = collections.OrderedDict()\n",
    "\n",
    "    # Logging.\n",
    "    print(f\"Post-processing {len(examples)} example predictions split into {len(features['input_ids'])} features.\")\n",
    "\n",
    "    # Let's loop over all the examples!\n",
    "    for example_index, example in examples.iterrows():\n",
    "        # Those are the indices of the features associated to the current example.\n",
    "        feature_indices = features_per_example[example_index]\n",
    "        min_null_score = None # Only used if squad_v2 is True.\n",
    "        valid_answers = []\n",
    "        \n",
    "        context = example['context']\n",
    "        # Looping through all the features associated to the current example.\n",
    "        for feature_index in feature_indices:\n",
    "            # We grab the predictions of the model for this feature.\n",
    "            start_logits = all_start_logits[feature_index]\n",
    "            end_logits = all_end_logits[feature_index]\n",
    "            # This is what will allow us to map some the positions in our logits to span of texts in the original\n",
    "            # context.\n",
    "            offset_mapping = features['offset_mapping'][feature_index]\n",
    "\n",
    "            # Update minimum null prediction.\n",
    "            cls_index = features['input_ids'][feature_index].index(tokenizer.cls_token_id)\n",
    "            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n",
    "            if min_null_score is None or min_null_score < feature_null_score:\n",
    "                min_null_score = feature_null_score\n",
    "\n",
    "            # Go through all possibilities for the `n_best_size` greater start and end logits.\n",
    "            start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n",
    "                    # to part of the input_ids that are not in the context.\n",
    "                    if (\n",
    "                        start_index >= len(offset_mapping)\n",
    "                        or end_index >= len(offset_mapping)\n",
    "                        or offset_mapping[start_index] is None\n",
    "                        or offset_mapping[end_index] is None\n",
    "                    ):\n",
    "                        continue\n",
    "                    # Don't consider answers with a length that is either < 0 or > max_answer_length.\n",
    "                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
    "                        continue\n",
    "\n",
    "                    start_char = offset_mapping[start_index][0]\n",
    "                    end_char = offset_mapping[end_index][1]\n",
    "                    valid_answers.append(\n",
    "                        {\n",
    "                            \"score\": start_logits[start_index] + end_logits[end_index],\n",
    "                            \"text\": context[start_char: end_char]\n",
    "                        }\n",
    "                    )\n",
    "        \n",
    "        if len(valid_answers) > 0:\n",
    "            best_answer = sorted(valid_answers, key = lambda x: x[\"score\"], reverse=True)[0]\n",
    "        else:\n",
    "            # In the very rare edge case we have not a single non-null prediction, we create a fake prediction to avoid\n",
    "            # failure.\n",
    "            best_answer = {\"text\": \"\", \"score\": 0.0}\n",
    "        \n",
    "        # Let's pick our final answer: the best one or the null answer (only for squad_v2)\n",
    "        #if not squad_v2:\n",
    "        #    predictions[example[\"id\"]] = best_answer[\"text\"]\n",
    "        #else:\n",
    "        answer = best_answer[\"text\"] \n",
    "        predictions[example['id']] = answer\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.046069,
     "end_time": "2021-09-03T05:38:28.260211",
     "exception": false,
     "start_time": "2021-09-03T05:38:28.214142",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Fine Tune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-03T05:38:28.367949Z",
     "iopub.status.busy": "2021-09-03T05:38:28.361557Z",
     "iopub.status.idle": "2021-09-03T07:16:43.200264Z",
     "shell.execute_reply": "2021-09-03T07:16:43.199639Z",
     "shell.execute_reply.started": "2021-09-01T07:14:10.741125Z"
    },
    "papermill": {
     "duration": 5894.893819,
     "end_time": "2021-09-03T07:16:43.200487",
     "exception": false,
     "start_time": "2021-09-03T05:38:28.306668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################################################################################################################\n",
      "Fold: 1\n",
      "#######################################################################################################################################\n",
      "(11073, 6) (223, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at ../input/jplu-tf-xlm-roberta-large were not used when initializing TFXLMRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFXLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFXLMRobertaModel were initialized from the model checkpoint at ../input/jplu-tf-xlm-roberta-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_mask (InputLayer)     [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tfxlm_roberta_model (TFXLMRober TFBaseModelOutputWit 559890432   input_ids[0][0]                  \n",
      "                                                                 attention_mask[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_73 (Dropout)            (None, 512, 1024)    0           tfxlm_roberta_model[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_74 (Dropout)            (None, 512, 1024)    0           tfxlm_roberta_model[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512, 1)       1024        dropout_73[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512, 1)       1024        dropout_74[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 512)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 512)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "start_positions (Activation)    (None, 512)          0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "end_positions (Activation)      (None, 512)          0           flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 559,892,480\n",
      "Trainable params: 559,892,480\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "1188/1188 [==============================] - 400s 220ms/step - loss: 4.7914 - start_positions_loss: 2.3159 - end_positions_loss: 2.4755\n",
      "\n",
      "Epoch 00001: loss improved from inf to 3.33929, saving model to qa_model_1.h5\n",
      "Epoch 2/3\n",
      "1188/1188 [==============================] - 262s 220ms/step - loss: 1.7967 - start_positions_loss: 0.8060 - end_positions_loss: 0.9908\n",
      "\n",
      "Epoch 00002: loss improved from 3.33929 to 1.85064, saving model to qa_model_1.h5\n",
      "Epoch 3/3\n",
      "1188/1188 [==============================] - 263s 221ms/step - loss: 1.3247 - start_positions_loss: 0.5676 - end_positions_loss: 0.7570\n",
      "\n",
      "Epoch 00003: loss improved from 1.85064 to 1.33416, saving model to qa_model_1.h5\n",
      "Predicting valid dataset...\n",
      "113/113 [==============================] - 23s 147ms/step\n",
      "(1796, 512) (1796, 512)\n",
      "Post-process predictions...\n",
      "Post-processing 223 example predictions split into 1796 features.\n",
      "Jaccard Score for fold 1: 0.6120468470244254\n",
      "#######################################################################################################################################\n",
      "Fold: 2\n",
      "#######################################################################################################################################\n",
      "(11073, 6) (223, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at ../input/jplu-tf-xlm-roberta-large were not used when initializing TFXLMRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFXLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFXLMRobertaModel were initialized from the model checkpoint at ../input/jplu-tf-xlm-roberta-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1182/1182 [==============================] - 407s 221ms/step - loss: 3.8369 - start_positions_loss: 1.7824 - end_positions_loss: 2.0545\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.93918, saving model to qa_model_2.h5\n",
      "Epoch 2/3\n",
      "1182/1182 [==============================] - 262s 221ms/step - loss: 1.8268 - start_positions_loss: 0.8185 - end_positions_loss: 1.0083\n",
      "\n",
      "Epoch 00002: loss improved from 2.93918 to 1.83063, saving model to qa_model_2.h5\n",
      "Epoch 3/3\n",
      "1182/1182 [==============================] - 262s 221ms/step - loss: 1.3191 - start_positions_loss: 0.5800 - end_positions_loss: 0.7391\n",
      "\n",
      "Epoch 00003: loss improved from 1.83063 to 1.60011, saving model to qa_model_2.h5\n",
      "Predicting valid dataset...\n",
      "118/118 [==============================] - 23s 146ms/step\n",
      "(1881, 512) (1881, 512)\n",
      "Post-process predictions...\n",
      "Post-processing 223 example predictions split into 1881 features.\n",
      "Jaccard Score for fold 2: 0.6460665268961234\n",
      "#######################################################################################################################################\n",
      "Fold: 3\n",
      "#######################################################################################################################################\n",
      "(11073, 6) (223, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at ../input/jplu-tf-xlm-roberta-large were not used when initializing TFXLMRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFXLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFXLMRobertaModel were initialized from the model checkpoint at ../input/jplu-tf-xlm-roberta-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1163/1163 [==============================] - 405s 221ms/step - loss: 4.0576 - start_positions_loss: 1.9217 - end_positions_loss: 2.1359\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.98471, saving model to qa_model_3.h5\n",
      "Epoch 2/3\n",
      "1163/1163 [==============================] - 258s 221ms/step - loss: 7.9754 - start_positions_loss: 3.9512 - end_positions_loss: 4.0243\n",
      "\n",
      "Epoch 00002: loss did not improve from 2.98471\n",
      "Epoch 3/3\n",
      "1163/1163 [==============================] - 257s 221ms/step - loss: 12.4909 - start_positions_loss: 6.2455 - end_positions_loss: 6.2454\n",
      "\n",
      "Epoch 00003: loss did not improve from 2.98471\n",
      "Predicting valid dataset...\n",
      "138/138 [==============================] - 24s 129ms/step\n",
      "(2195, 512) (2195, 512)\n",
      "Post-process predictions...\n",
      "Post-processing 223 example predictions split into 2195 features.\n",
      "Jaccard Score for fold 3: 0.005749373202895849\n",
      "#######################################################################################################################################\n",
      "Fold: 4\n",
      "#######################################################################################################################################\n",
      "(11073, 6) (223, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at ../input/jplu-tf-xlm-roberta-large were not used when initializing TFXLMRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFXLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFXLMRobertaModel were initialized from the model checkpoint at ../input/jplu-tf-xlm-roberta-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1174/1174 [==============================] - 405s 221ms/step - loss: 4.0908 - start_positions_loss: 1.9283 - end_positions_loss: 2.1625\n",
      "\n",
      "Epoch 00001: loss improved from inf to 3.01355, saving model to qa_model_4.h5\n",
      "Epoch 2/3\n",
      "1174/1174 [==============================] - 260s 221ms/step - loss: 1.7733 - start_positions_loss: 0.7920 - end_positions_loss: 0.9813\n",
      "\n",
      "Epoch 00002: loss improved from 3.01355 to 1.90650, saving model to qa_model_4.h5\n",
      "Epoch 3/3\n",
      "1174/1174 [==============================] - 262s 222ms/step - loss: 1.6733 - start_positions_loss: 0.7284 - end_positions_loss: 0.9449\n",
      "\n",
      "Epoch 00003: loss improved from 1.90650 to 1.53029, saving model to qa_model_4.h5\n",
      "Predicting valid dataset...\n",
      "126/126 [==============================] - 24s 138ms/step\n",
      "(2015, 512) (2015, 512)\n",
      "Post-process predictions...\n",
      "Post-processing 223 example predictions split into 2015 features.\n",
      "Jaccard Score for fold 4: 0.6117411176267679\n",
      "#######################################################################################################################################\n",
      "Fold: 5\n",
      "#######################################################################################################################################\n",
      "(11074, 6) (222, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at ../input/jplu-tf-xlm-roberta-large were not used when initializing TFXLMRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFXLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFXLMRobertaModel were initialized from the model checkpoint at ../input/jplu-tf-xlm-roberta-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1180/1180 [==============================] - 407s 221ms/step - loss: 4.4448 - start_positions_loss: 2.1030 - end_positions_loss: 2.3418\n",
      "\n",
      "Epoch 00001: loss improved from inf to 3.10608, saving model to qa_model_5.h5\n",
      "Epoch 2/3\n",
      "1180/1180 [==============================] - 261s 221ms/step - loss: 1.8221 - start_positions_loss: 0.8176 - end_positions_loss: 1.0046\n",
      "\n",
      "Epoch 00002: loss improved from 3.10608 to 1.85803, saving model to qa_model_5.h5\n",
      "Epoch 3/3\n",
      "1180/1180 [==============================] - 262s 221ms/step - loss: 1.3871 - start_positions_loss: 0.6108 - end_positions_loss: 0.7763\n",
      "\n",
      "Epoch 00003: loss improved from 1.85803 to 1.42921, saving model to qa_model_5.h5\n",
      "Predicting valid dataset...\n",
      "121/121 [==============================] - 23s 139ms/step\n",
      "(1923, 512) (1923, 512)\n",
      "Post-process predictions...\n",
      "Post-processing 222 example predictions split into 1923 features.\n",
      "Jaccard Score for fold 5: 0.6160231660231661\n"
     ]
    }
   ],
   "source": [
    "strart_probs, end_probs = [], []\n",
    "epochs = hparams['EPOCHS']\n",
    "jaccard_scores = []\n",
    "\n",
    "for i, fold in enumerate(range(n_folds)):\n",
    "    print('#########' * 15)\n",
    "    print(f\"Fold: {fold + 1}\")\n",
    "    print('#########' * 15)\n",
    "    train_df = train[train['kfold'] != fold]\n",
    "    valid_df = train[train['kfold'] == fold]\n",
    "    \n",
    "    #concat external_df to train_df for training, no change in valid_df\n",
    "    train_df = pd.concat([train_df.iloc[:, 1:-1], external_df])\n",
    "\n",
    "    train_df = train_df.reset_index(drop = True)\n",
    "    valid_df = valid_df.reset_index(drop = True)\n",
    "    print(train_df.shape, valid_df.shape)\n",
    "    \n",
    "    train_dataset, train_enc = build_tf_dataset(train_df, batch_size = batch_size, flag = 'train')\n",
    "    valid_dataset, valid_enc = build_tf_dataset(valid_df, batch_size = batch_size, flag = 'valid')\n",
    "    \n",
    "    K.clear_session()\n",
    "    \n",
    "    with strategy.scope():\n",
    "        model = build_model()\n",
    "    if i == 0:\n",
    "        print(model.summary())\n",
    "    \n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(f'qa_model_{fold + 1}.h5', verbose = 1, monitor = 'loss', mode = 'min', save_best_only = True, \n",
    "                                                save_weights_only = True)\n",
    "\n",
    "    history = model.fit(train_dataset, \n",
    "                        epochs = epochs, \n",
    "                        batch_size = batch_size,\n",
    "                        callbacks = [checkpoint],\n",
    "                        verbose = 1\n",
    "                        )\n",
    "    print('Predicting valid dataset...')\n",
    "    start_pred, end_pred = model.predict(valid_dataset, batch_size = batch_size, verbose = 1)\n",
    "    print(start_pred.shape, end_pred.shape)\n",
    "    print('Post-process predictions...')\n",
    "    valid_preds = post_process_predictions(valid_df, valid_enc, start_pred, end_pred)\n",
    "    \n",
    "    score = []\n",
    "    for idx in range(len(valid_df)):\n",
    "        str1 = valid_df['answer_text'].values[idx]\n",
    "        str2 = valid_preds[valid_df.loc[idx, 'id']]\n",
    "        score.append(jaccard(str1, str2))\n",
    "    print(f'Jaccard Score for fold {fold + 1}: {np.mean(score)}')\n",
    "    jaccard_scores.append(np.mean(score))\n",
    "    \n",
    "    strart_probs.append(start_pred)\n",
    "    end_probs.append(end_pred)\n",
    "    \n",
    "    del train_dataset, valid_dataset, model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 5.477761,
     "end_time": "2021-09-03T07:16:54.246159",
     "exception": false,
     "start_time": "2021-09-03T07:16:48.768398",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Save the hyperparameters and the validation scores for prediction notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-03T07:17:05.369340Z",
     "iopub.status.busy": "2021-09-03T07:17:05.368638Z",
     "iopub.status.idle": "2021-09-03T07:17:05.371443Z",
     "shell.execute_reply": "2021-09-03T07:17:05.370926Z"
    },
    "papermill": {
     "duration": 5.538311,
     "end_time": "2021-09-03T07:17:05.371581",
     "exception": false,
     "start_time": "2021-09-03T07:16:59.833270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hparams['JAC_SCORES'] = jaccard_scores\n",
    "\n",
    "with open(r'hparams.yaml', 'w') as f:\n",
    "    yaml.dump(hparams, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 5.609387,
     "end_time": "2021-09-03T07:17:16.531293",
     "exception": false,
     "start_time": "2021-09-03T07:17:10.921906",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Predict on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-03T07:17:27.686575Z",
     "iopub.status.busy": "2021-09-03T07:17:27.685565Z",
     "iopub.status.idle": "2021-09-03T07:17:28.149589Z",
     "shell.execute_reply": "2021-09-03T07:17:28.148892Z",
     "shell.execute_reply.started": "2021-08-31T06:41:20.686896Z"
    },
    "papermill": {
     "duration": 6.025189,
     "end_time": "2021-09-03T07:17:28.149735",
     "exception": false,
     "start_time": "2021-09-03T07:17:22.124546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset, test_enc = build_tf_dataset(test, batch_size = batch_size, flag = 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-03T07:17:39.204230Z",
     "iopub.status.busy": "2021-09-03T07:17:39.203591Z",
     "iopub.status.idle": "2021-09-03T07:30:13.449804Z",
     "shell.execute_reply": "2021-09-03T07:30:13.448377Z",
     "shell.execute_reply.started": "2021-08-31T06:41:22.835859Z"
    },
    "papermill": {
     "duration": 759.766206,
     "end_time": "2021-09-03T07:30:13.449950",
     "exception": false,
     "start_time": "2021-09-03T07:17:33.683744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at ../input/jplu-tf-xlm-roberta-large were not used when initializing TFXLMRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFXLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFXLMRobertaModel were initialized from the model checkpoint at ../input/jplu-tf-xlm-roberta-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained model weights...\n",
      "Predicting testset - Fold: 1...\n",
      "3/3 [==============================] - 18s 6s/step\n",
      "(45, 512) (45, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at ../input/jplu-tf-xlm-roberta-large were not used when initializing TFXLMRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFXLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFXLMRobertaModel were initialized from the model checkpoint at ../input/jplu-tf-xlm-roberta-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained model weights...\n",
      "Predicting testset - Fold: 2...\n",
      "3/3 [==============================] - 20s 6s/step\n",
      "(45, 512) (45, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at ../input/jplu-tf-xlm-roberta-large were not used when initializing TFXLMRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFXLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFXLMRobertaModel were initialized from the model checkpoint at ../input/jplu-tf-xlm-roberta-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained model weights...\n",
      "Predicting testset - Fold: 3...\n",
      "3/3 [==============================] - 18s 6s/step\n",
      "(45, 512) (45, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at ../input/jplu-tf-xlm-roberta-large were not used when initializing TFXLMRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFXLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFXLMRobertaModel were initialized from the model checkpoint at ../input/jplu-tf-xlm-roberta-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained model weights...\n",
      "Predicting testset - Fold: 4...\n",
      "3/3 [==============================] - 18s 6s/step\n",
      "(45, 512) (45, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at ../input/jplu-tf-xlm-roberta-large were not used when initializing TFXLMRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFXLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFXLMRobertaModel were initialized from the model checkpoint at ../input/jplu-tf-xlm-roberta-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained model weights...\n",
      "Predicting testset - Fold: 5...\n",
      "3/3 [==============================] - 18s 6s/step\n",
      "(45, 512) (45, 512)\n"
     ]
    }
   ],
   "source": [
    "start_probs, end_probs = [], []\n",
    "for fold in range(n_folds):\n",
    "    with strategy.scope():\n",
    "        model = build_model()\n",
    "    print('Loading trained model weights...')\n",
    "    model.load_weights(f'qa_model_{fold + 1}.h5')\n",
    "    print(f'Predicting testset - Fold: {fold + 1}...')\n",
    "    start_pred, end_pred = model.predict(test_dataset, batch_size = batch_size, verbose = 1)\n",
    "    print(start_pred.shape, end_pred.shape)\n",
    "    start_probs.append(start_pred)\n",
    "    end_probs.append(end_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-03T07:30:24.678889Z",
     "iopub.status.busy": "2021-09-03T07:30:24.678203Z",
     "iopub.status.idle": "2021-09-03T07:30:24.705774Z",
     "shell.execute_reply": "2021-09-03T07:30:24.706459Z",
     "shell.execute_reply.started": "2021-08-31T06:53:17.82387Z"
    },
    "papermill": {
     "duration": 5.549436,
     "end_time": "2021-09-03T07:30:24.706676",
     "exception": false,
     "start_time": "2021-09-03T07:30:19.157240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-processing 5 example predictions split into 45 features.\n"
     ]
    }
   ],
   "source": [
    "test_start_probs, test_end_probs = np.mean(start_probs, axis = 0), np.mean(end_probs, axis = 0)\n",
    "predictions = post_process_predictions(test, test_enc, test_start_probs, test_end_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-03T07:30:35.803502Z",
     "iopub.status.busy": "2021-09-03T07:30:35.802709Z",
     "iopub.status.idle": "2021-09-03T07:30:35.828683Z",
     "shell.execute_reply": "2021-09-03T07:30:35.828100Z",
     "shell.execute_reply.started": "2021-08-31T06:53:20.892517Z"
    },
    "papermill": {
     "duration": 5.5634,
     "end_time": "2021-09-03T07:30:35.828821",
     "exception": false,
     "start_time": "2021-09-03T07:30:30.265421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22bff3dec</td>\n",
       "      <td>येलन</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>282758170</td>\n",
       "      <td>20 अप्रैल 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d60987e0e</td>\n",
       "      <td>१२ मार्च १८२४</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f99c770dc</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40dec1964</td>\n",
       "      <td>சுவாமிநாதன் மற்றும் வர்கீஸ் குரியன்</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                     PredictionString\n",
       "0  22bff3dec                                 येलन\n",
       "1  282758170                       20 अप्रैल 2010\n",
       "2  d60987e0e                        १२ मार्च १८२४\n",
       "3  f99c770dc                                   13\n",
       "4  40dec1964  சுவாமிநாதன் மற்றும் வர்கீஸ் குரியன்"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = pd.DataFrame({'id': list(predictions.keys()), 'PredictionString': list(predictions.values())})\n",
    "sub_df.to_csv('./submission.csv', index = False)\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-03T07:30:47.003561Z",
     "iopub.status.busy": "2021-09-03T07:30:47.002596Z",
     "iopub.status.idle": "2021-09-03T07:30:47.006014Z",
     "shell.execute_reply": "2021-09-03T07:30:47.006740Z"
    },
    "papermill": {
     "duration": 5.598783,
     "end_time": "2021-09-03T07:30:47.006919",
     "exception": false,
     "start_time": "2021-09-03T07:30:41.408136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:53:20\n"
     ]
    }
   ],
   "source": [
    "finish = time()\n",
    "print(strftime(\"%H:%M:%S\", gmtime(finish - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 5.519259,
     "end_time": "2021-09-03T07:30:58.200170",
     "exception": false,
     "start_time": "2021-09-03T07:30:52.680911",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Thanks to Kaggle and fellow Kagglers for the all the learnings, nothing beats doing and learning!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6830.011624,
   "end_time": "2021-09-03T07:31:07.295800",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-09-03T05:37:17.284176",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
